# ğŸ¯ Stress Testing Suite - Quick Reference

## What Is This?

A comprehensive testing framework that validates your **RL-based Microgrid EMS + Anomaly Detection** system under:
- ğŸ² Edge cases (boundaries)
- ğŸ”¥ Extreme conditions (emergencies)  
- ğŸŒ Real-world scenarios (Indian patterns)
- âš¡ Performance limits (speed & scale)

---

## ğŸš€ How to Use

### Just Want to Test Quickly?
```bash
cd stress_testing
python quick_start.py
```
**Takes**: 2-5 minutes  
**Tests**: 5 essential scenarios  
**Use**: During development

---

### Need Complete Validation?
```bash
python run_all_tests.py
```
**Takes**: 15-45 minutes  
**Tests**: All 29 tests  
**Use**: Before deployment

---

### Short on Time?
```bash
python run_all_tests.py --skip-performance
```
**Takes**: 10-25 minutes  
**Tests**: 24 tests (skips performance)  
**Use**: Quick full validation

---

## ğŸ“Š What Gets Tested?

### 1ï¸âƒ£ Edge Cases (7 tests)
Can your system handle extremes?
- No solar/wind (night/cloudy)
- Max renewable (perfect conditions)
- Sudden load spikes
- Grid failures
- Wild price swings
- Battery stress

### 2ï¸âƒ£ Extreme Conditions (8 tests)
Will your system survive emergencies?
- 45Â°C heat waves
- 7-day rain (no solar)
- Equipment failures
- Multiple anomalies
- Grid blackouts
- Bad sensor data

### 3ï¸âƒ£ Real-World Scenarios (9 tests)
Works with actual Indian patterns?
- Monsoon season
- Summer peak (42Â°C)
- Diwali festival loads
- Industrial shifts
- Irrigation pumps
- Urban/rural patterns
- Power cuts
- EV charging surges

### 4ï¸âƒ£ Performance (5 tests)
Is it fast and efficient?
- Execution speed
- Memory usage
- Scalability
- Concurrent instances
- Real-time capability

---

## ğŸ“ˆ Understanding Results

### Test Status Indicators
- âœ… **PASS** - Everything worked perfectly
- âš ï¸ **FAIL** - Issues but system survived
- ğŸ”´ **CRITICAL** - System crashed (must fix!)

### Success Grades
After all tests:
- ğŸŒŸ **A+ (95%+)** - Production-ready! Deploy with confidence
- âœ¨ **A (90-95%)** - Very good, minor tweaks needed
- ğŸ‘ **B (80-90%)** - Good, some improvements needed
- âš ï¸ **C (70-80%)** - Acceptable, but needs work
- ğŸ”§ **D (<70%)** - Not ready, significant issues

---

## ğŸ“ Where Are Results?

After running tests, check:
```
stress_testing/results/
â”œâ”€â”€ quick_test/              # Quick validation
â”œâ”€â”€ edge_cases/              # Edge case results
â”œâ”€â”€ extreme_conditions/      # Emergency scenarios
â”œâ”€â”€ real_world/              # Indian patterns
â”œâ”€â”€ performance/             # Speed & memory
â””â”€â”€ master/                  # Overall summary â­
```

Open the latest JSON file in `master/` for overall stats.

---

## ğŸ“ Example: Reading a Result

```json
{
  "overall_statistics": {
    "total_tests": 29,
    "total_passed": 27,
    "total_failed": 2,
    "success_rate": 93.1
  }
}
```

This means:
- âœ… 93.1% success (Grade: A - Very Good)
- âš ï¸ 2 tests failed (review details)
- ğŸš€ System is production-ready with minor fixes

---

## ğŸ”¥ Common Use Cases

### "I just changed some code"
```bash
python quick_start.py
```
Quick check (5 min)

### "About to commit to git"
```bash
python test_edge_cases.py
```
Edge case check (5 min)

### "Ready to deploy"
```bash
python run_all_tests.py
```
Full validation (30 min)

### "Need to optimize performance"
```bash
python test_performance.py
```
Performance focus (10 min)

### "Testing for Indian conditions"
```bash
python test_real_world_scenarios.py
```
Real-world patterns (15 min)

---

## âš ï¸ What If Tests Fail?

### Critical Failures ğŸ”´
**What**: System crashed  
**Action**: Must fix immediately  
**Don't**: Deploy to production

### Regular Failures âš ï¸
**What**: System survived but struggled  
**Action**: Review and improve  
**OK**: Can deploy if acceptable

### All Pass âœ…
**What**: Everything worked  
**Action**: You're good to go!  
**Celebrate**: ğŸ‰

---

## ğŸ’¡ Pro Tips

1. **Run `quick_start.py` often** - Fast feedback loop
2. **Check `master/` folder** - Best overall summary
3. **Fix critical failures first** - Don't ignore crashes
4. **Use `--skip-performance`** - When in a hurry
5. **Save results** - Track improvement over time

---

## ğŸ†˜ Troubleshooting

### "Import errors"
Make sure you're in the right folder:
```bash
cd d:\IIT_GAN\Version_2\microgrid-ems-drl\stress_testing
```

### "Too slow"
Use quick start or skip performance:
```bash
python quick_start.py
# OR
python run_all_tests.py --skip-performance
```

### "Out of memory"
Run individual suites:
```bash
python test_edge_cases.py
python test_real_world_scenarios.py
```

---

## ğŸ“ Quick Command Reference

| Command | Time | What It Does |
|---------|------|--------------|
| `python quick_start.py` | 5 min | Quick validation |
| `python test_edge_cases.py` | 5 min | Edge cases only |
| `python test_extreme_conditions.py` | 10 min | Emergency tests |
| `python test_real_world_scenarios.py` | 15 min | Indian patterns |
| `python test_performance.py` | 10 min | Speed & memory |
| `python run_all_tests.py` | 30-45 min | Everything |
| `python run_all_tests.py --skip-performance` | 20-30 min | Skip perf tests |

---

## âœ¨ That's It!

You now have a complete stress testing suite. Start with `quick_start.py` and work your way up to full testing.

**Questions?** Check `README.md` for detailed documentation.

**Ready?** Let's test!
```bash
cd stress_testing
python quick_start.py
```

ğŸš€ **Good luck!**
