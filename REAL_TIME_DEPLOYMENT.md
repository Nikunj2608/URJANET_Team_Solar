# ğŸ“¡ Real-Time Deployment Guide: Handling New Incoming Data

## Overview
You trained the RL model on **past 10 years of data**. Now you want to deploy it to handle **new incoming data in real-time**. This guide explains how.

---

## ğŸ¤” The Big Question: "What About New Data?"

### **Current State**: Trained on Past Data
```
Training Data (2015-2025): [â—â—â—â—â—â—â—â—â—â—] â† Model learned from this
                           10 years
```

### **Deployment Goal**: Handle New Data
```
Real-Time Operation:  â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€â—â”€â”€â”€â”€> Time
                        15min 30min 45min 1hr
                        New   New   New   New
                        data  data  data  data
```

**Your questions**:
1. â“ Does the model need to be retrained for every new data point?
2. â“ How does it handle data it has never seen?
3. â“ What if solar/wind patterns change over time?
4. â“ How do we connect to real sensors?

---

## âœ… Answer: No Retraining Needed (Usually)

### **How RL Models Work in Production**

**Training Phase** (What you already did):
```python
# You trained for 1000 episodes
for episode in range(1000):
    obs = env.reset()
    for step in range(96):  # 24 hours
        action = agent.select_action(obs)
        next_obs, reward, done, info = env.step(action)
        # Agent learned patterns
```

**Deployment Phase** (What happens now):
```python
# Load trained model
agent.load("models/best_model.pt")

# Run forever on new data
while True:
    # Get CURRENT state from real sensors
    obs = get_current_state_from_sensors()  # NEW DATA!
    
    # Agent makes decision (NO TRAINING!)
    action = agent.select_action(obs, deterministic=True)
    
    # Send action to real hardware
    execute_action_on_microgrid(action)
    
    # Wait 15 minutes
    time.sleep(15 * 60)
```

**Key insight**: 
- âœ… Model uses learned patterns to handle new data
- âœ… No retraining needed for normal operation
- âœ… Just feed new observations â†’ get actions

---

## ğŸ§  Why It Works: Generalization

### **What Model Learned** (During Training):
```
Pattern Recognition:
â€¢ "High solar + low price â†’ Charge battery"
â€¢ "Evening + high price â†’ Discharge battery"
â€¢ "Low SoC + no renewable â†’ Charge from grid"
â€¢ "High SoC + excess solar â†’ Export to grid"
```

### **What Model Does** (With New Data):
```
New situation: Solar = 1,800 kW, Price = â‚¹2.50/kWh, Battery SoC = 40%

Model thinks:
1. "I've seen similar situations in training"
2. "Solar is high (like pattern #1)"
3. "Price is low (like pattern #1)"
4. "Battery has room (SoC < 80%)"
5. â†’ Decision: Charge battery at 600 kW âœ“

This is NEW data, but model recognizes the PATTERN.
```

---

## ğŸ“Š Deployment Architecture

### **System Overview**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PHYSICAL MICROGRID                           â”‚
â”‚                                                                  â”‚
â”‚  [Solar] [Wind] [Battery] [Grid] [Load] [EVs]                  â”‚
â”‚     â†“      â†“       â†“        â†“       â†“      â†“                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚         SENSORS & METERS                    â”‚                â”‚
â”‚  â”‚  (Measure real-time power, voltage, SoC)   â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ Data (every 15 min or 1 sec)
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATA ACQUISITION LAYER                          â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  SCADA/IoT   â”‚  â”‚  Weather API â”‚  â”‚  Grid Price  â”‚          â”‚
â”‚  â”‚  (Modbus)    â”‚  â”‚  (Solar/Wind)â”‚  â”‚  API         â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ Raw sensor data
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATA PREPROCESSING                              â”‚
â”‚                                                                   â”‚
â”‚  â€¢ Validate data (check for outliers/errors)                     â”‚
â”‚  â€¢ Normalize (same scale as training data)                       â”‚
â”‚  â€¢ Create observation vector (90 dimensions)                     â”‚
â”‚  â€¢ Add forecasts (2-hour ahead prediction)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ obs = [90 values]
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   RL AGENT (Your Trained Model)                   â”‚
â”‚                                                                   â”‚
â”‚  model = load("best_model.pt")                                   â”‚
â”‚  action = model.predict(obs)    â† NO TRAINING HERE!             â”‚
â”‚                                                                   â”‚
â”‚  action = [battery_1, battery_2, grid, ev, curtail]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ Control commands
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SAFETY SUPERVISOR                               â”‚
â”‚                                                                   â”‚
â”‚  â€¢ Check if action violates safety limits                        â”‚
â”‚  â€¢ Clamp to safe ranges                                          â”‚
â”‚  â€¢ Log any violations                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ Safe action
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CONTROL EXECUTION LAYER                         â”‚
â”‚                                                                   â”‚
â”‚  â€¢ Send commands to battery inverters                            â”‚
â”‚  â€¢ Control grid connection                                       â”‚
â”‚  â€¢ Manage EV chargers                                            â”‚
â”‚  â€¢ Apply curtailment to renewables                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ Physical actions
                        â†“
        [Battery charges/discharges, grid import/export, etc.]
```

---

## ğŸ”§ Implementation: 3 Deployment Modes

### **Mode 1: Simulation (Testing)**
Use for: Testing your model before deploying to real hardware

```python
# deployment/simulation_mode.py

import torch
import pandas as pd
from train_ppo_improved import ImprovedPPOAgent
from microgrid_env import MicrogridEMSEnv

# Load trained model
agent = ImprovedPPOAgent(obs_dim=90, action_dim=5)
agent.load("models/best_model.pt")

# Load NEW data (e.g., 2026 data, model never saw this!)
new_pv = pd.read_csv('data/NEW_2026_pv.csv')
new_wt = pd.read_csv('data/NEW_2026_wt.csv')
new_load = pd.read_csv('data/NEW_2026_load.csv')
new_price = pd.read_csv('data/NEW_2026_price.csv')

# Create environment with NEW data
env = MicrogridEMSEnv(new_pv, new_wt, new_load, new_price)

# Run for 1 day (96 steps)
obs = env.reset()
total_cost = 0

for step in range(96):
    # Agent makes decision (NO TRAINING!)
    action = agent.select_action(obs, deterministic=True)
    
    # Environment processes action
    next_obs, reward, done, info = env.step(action)
    
    # Log results
    total_cost += info['cost']
    print(f"Step {step}: Cost = â‚¹{info['cost']:.2f}, "
          f"Emissions = {info['emissions']:.2f} kg")
    
    obs = next_obs
    
    if done:
        break

print(f"\nTotal cost: â‚¹{total_cost:.2f}")
```

**Key points**:
- âœ… Model sees NEW data (2026, not in training)
- âœ… No training happens (model frozen)
- âœ… Tests if model generalizes well

---

### **Mode 2: Real-Time (Production)**
Use for: Deploying to actual hardware

```python
# deployment/realtime_mode.py

import torch
import time
from datetime import datetime
from train_ppo_improved import ImprovedPPOAgent
from safety_supervisor import SafetySupervisor
import requests  # For API calls

# ===== INITIALIZATION =====

# Load trained model
agent = ImprovedPPOAgent(obs_dim=90, action_dim=5)
agent.load("models/best_model.pt")

# Load safety supervisor
safety = SafetySupervisor()

# Initialize normalizer (MUST use same stats from training!)
normalizer_mean = torch.load("models/best_model_normalizer_mean.pt")
normalizer_std = torch.load("models/best_model_normalizer_std.pt")

# ===== DATA COLLECTION FUNCTIONS =====

def get_solar_power():
    """Get current solar generation from sensor"""
    # Option 1: Read from SCADA system
    response = requests.get("http://microgrid-scada/api/solar/power")
    return response.json()['power_kw']
    
    # Option 2: Read from IoT device (e.g., Modbus)
    # from pymodbus.client import ModbusTcpClient
    # client = ModbusTcpClient('192.168.1.100')
    # result = client.read_holding_registers(0, 1)
    # return result.registers[0] / 10  # Convert to kW

def get_wind_power():
    """Get current wind generation from sensor"""
    response = requests.get("http://microgrid-scada/api/wind/power")
    return response.json()['power_kw']

def get_load_power():
    """Get current load from sensor"""
    response = requests.get("http://microgrid-scada/api/load/power")
    return response.json()['power_kw']

def get_battery_state():
    """Get battery SoC and SoH"""
    response = requests.get("http://microgrid-scada/api/battery/status")
    data = response.json()
    return data['soc'], data['soh']

def get_grid_price():
    """Get current grid price"""
    response = requests.get("http://utility-api/api/price/current")
    return response.json()['price_per_kwh']

def get_weather_forecast():
    """Get 2-hour ahead weather forecast"""
    response = requests.get("http://weather-api/forecast?hours=2")
    data = response.json()
    return {
        'solar_forecast': data['solar_irradiance'],
        'wind_forecast': data['wind_speed']
    }

def construct_observation():
    """Construct 90-dim observation vector from sensors"""
    
    # Get current measurements
    solar_power = get_solar_power()
    wind_power = get_wind_power()
    load_power = get_load_power()
    soc, soh = get_battery_state()
    price = get_grid_price()
    forecast = get_weather_forecast()
    
    # Get temporal features
    now = datetime.now()
    hour = now.hour
    minute = now.minute
    day_of_week = now.weekday()
    
    # Build observation (must match training format!)
    obs = [
        # Temporal (10 dims)
        hour / 24.0,                    # Normalized hour
        minute / 60.0,                  # Normalized minute
        day_of_week / 7.0,              # Normalized day
        np.sin(2 * np.pi * hour / 24),  # Hour sin
        np.cos(2 * np.pi * hour / 24),  # Hour cos
        # ... (5 more temporal features)
        
        # PV (10 dims)
        solar_power / 3000.0,           # Normalized current
        forecast['solar_forecast'][0] / 3000.0,  # +15 min
        forecast['solar_forecast'][1] / 3000.0,  # +30 min
        # ... (7 more PV features)
        
        # Wind (10 dims)
        wind_power / 1000.0,
        # ... (9 more wind features)
        
        # Load (10 dims)
        load_power / 2000.0,
        # ... (9 more load features)
        
        # Battery (20 dims)
        soc,  # Already 0-1
        soh,
        # ... (18 more battery features)
        
        # Grid (10 dims)
        price / 10.0,  # Normalize price
        # ... (9 more grid features)
        
        # EV (10 dims)
        # ... (10 EV features)
        
        # Health (10 dims)
        # ... (10 health features)
        
        # Previous actions (10 dims)
        # ... (10 action history features)
    ]
    
    return np.array(obs, dtype=np.float32)

def execute_action(action):
    """Send action to physical hardware"""
    
    battery_1_power = action[0]  # kW
    battery_2_power = action[1]
    grid_power = action[2]
    ev_power = action[3]
    curtailment = action[4]
    
    # Send to battery inverter
    requests.post("http://microgrid-scada/api/battery1/setpower", 
                  json={'power_kw': battery_1_power})
    requests.post("http://microgrid-scada/api/battery2/setpower",
                  json={'power_kw': battery_2_power})
    
    # Send to grid controller
    requests.post("http://microgrid-scada/api/grid/setpower",
                  json={'power_kw': grid_power})
    
    # Send to EV charger
    requests.post("http://microgrid-scada/api/ev/setpower",
                  json={'power_kw': ev_power})
    
    # Send curtailment command
    requests.post("http://microgrid-scada/api/renewable/curtail",
                  json={'curtail_ratio': curtailment})

# ===== MAIN CONTROL LOOP =====

def main():
    print("ğŸš€ Starting RL Agent in REAL-TIME MODE")
    print("â° Control interval: 15 minutes")
    print("â”€" * 60)
    
    while True:
        try:
            # 1. Get current state from sensors
            obs = construct_observation()
            
            # 2. Normalize (CRITICAL! Must match training)
            obs_normalized = (obs - normalizer_mean) / (normalizer_std + 1e-8)
            
            # 3. Agent makes decision
            action = agent.select_action(obs_normalized, deterministic=True)
            
            # 4. Safety check
            action_safe, violations = safety.check_and_correct(action, obs)
            
            if violations:
                print(f"âš ï¸  Safety violations detected: {violations}")
            
            # 5. Execute action
            execute_action(action_safe)
            
            # 6. Log
            timestamp = datetime.now().isoformat()
            print(f"âœ“ {timestamp}: Action executed")
            print(f"  Battery: {action_safe[0]:.1f} kW, {action_safe[1]:.1f} kW")
            print(f"  Grid: {action_safe[2]:.1f} kW")
            print(f"  EV: {action_safe[3]:.1f} kW")
            
            # 7. Wait 15 minutes
            time.sleep(15 * 60)
            
        except Exception as e:
            print(f"âŒ Error: {e}")
            print("Reverting to safe mode (no action)")
            time.sleep(60)  # Wait 1 min before retry

if __name__ == "__main__":
    main()
```

**Key features**:
- âœ… Reads from real sensors every 15 min
- âœ… Uses trained model (no training)
- âœ… Sends commands to real hardware
- âœ… Safety checks before execution
- âœ… Error handling (falls back to safe mode)

---

### **Mode 3: Hybrid (Real-Time + Online Learning)**
Use for: Adapting to changing patterns over time

```python
# deployment/hybrid_mode.py

import torch
from collections import deque

# Load trained model
agent = ImprovedPPOAgent(obs_dim=90, action_dim=5)
agent.load("models/best_model.pt")

# Replay buffer for online learning
replay_buffer = deque(maxlen=10000)

# Thresholds for retraining
RETRAIN_THRESHOLD = 1000  # Retrain after 1000 new samples
PERFORMANCE_DROP_THRESHOLD = 0.2  # 20% worse than baseline

step_count = 0
baseline_performance = -53585  # From training

while True:
    # Get observation
    obs = construct_observation()
    
    # Agent acts
    action = agent.select_action(obs, deterministic=True)
    
    # Execute
    execute_action(action)
    
    # Wait and get result
    time.sleep(15 * 60)
    next_obs = construct_observation()
    reward = calculate_reward()  # Compute actual reward
    
    # Store experience
    replay_buffer.append((obs, action, reward, next_obs))
    step_count += 1
    
    # Check if we need to retrain
    if step_count >= RETRAIN_THRESHOLD:
        recent_performance = np.mean([r for _, _, r, _ in replay_buffer])
        
        if recent_performance < baseline_performance * (1 - PERFORMANCE_DROP_THRESHOLD):
            print("âš ï¸  Performance dropped! Retraining...")
            
            # Retrain on recent data
            agent.train_on_buffer(replay_buffer, epochs=10)
            
            # Save new model
            agent.save("models/best_model_updated.pt")
            
            baseline_performance = recent_performance
            step_count = 0
```

**When to use this**:
- âš ï¸ When microgrid characteristics change (new equipment)
- âš ï¸ When weather patterns shift (climate change)
- âš ï¸ When price structure changes (new tariffs)

**Caution**: Only retrain if performance degrades significantly!

---

## ğŸ“¡ Data Sources: Where New Data Comes From

### **1. SCADA System** (Supervisory Control and Data Acquisition)
```
Industrial standard for microgrid monitoring
â€¢ Protocols: Modbus TCP/RTU, DNP3, IEC 61850
â€¢ Frequency: 1-second resolution
â€¢ Data: Real-time power, voltage, current, frequency
```

**Example**: Reading from Modbus
```python
from pymodbus.client import ModbusTcpClient

client = ModbusTcpClient('192.168.1.100', port=502)
result = client.read_holding_registers(address=0, count=10)

solar_power = result.registers[0] / 10  # kW
wind_power = result.registers[1] / 10
battery_soc = result.registers[2] / 100  # 0-1
```

### **2. IoT Sensors**
```
Low-cost sensors for monitoring
â€¢ Protocols: MQTT, HTTP REST API
â€¢ Frequency: 10-second to 1-minute
â€¢ Data: Temperature, irradiance, wind speed
```

**Example**: Reading from MQTT
```python
import paho.mqtt.client as mqtt

def on_message(client, userdata, msg):
    if msg.topic == "microgrid/solar/power":
        solar_power = float(msg.payload)
        # Use this value

client = mqtt.Client()
client.on_message = on_message
client.connect("mqtt.broker.com", 1883)
client.subscribe("microgrid/#")
client.loop_forever()
```

### **3. Weather APIs**
```
For forecasting (needed by your RL model)
â€¢ Services: OpenWeatherMap, NREL NSRDB, Visual Crossing
â€¢ Frequency: Every 15 minutes
â€¢ Data: 2-hour ahead solar irradiance, wind speed
```

**Example**: OpenWeatherMap API
```python
import requests

API_KEY = "your_api_key"
lat, lon = 28.6139, 77.2090  # Delhi

response = requests.get(
    f"https://api.openweathermap.org/data/2.5/forecast",
    params={'lat': lat, 'lon': lon, 'appid': API_KEY}
)

data = response.json()
next_2h_irradiance = [d['clouds']['all'] for d in data['list'][:2]]
```

### **4. Grid Price APIs**
```
For real-time pricing
â€¢ India: IEX (Indian Energy Exchange), POSOCO
â€¢ Frequency: Every 15 minutes
â€¢ Data: Current price, day-ahead prices
```

### **5. Database (Historical Storage)**
```
Store all data for analysis
â€¢ Time-series DB: InfluxDB, TimescaleDB
â€¢ Frequency: Every 15 minutes
â€¢ Purpose: Logs, analysis, retraining data
```

---

## ğŸ”„ Data Flow Timeline

### **Typical 15-Minute Cycle**:

```
00:00 â”€â”€â”€â”€> Get sensor data (5 sec)
            â€¢ Solar: 1,234 kW
            â€¢ Wind: 345 kW
            â€¢ Load: 1,567 kW
            â€¢ Battery SoC: 67%
            â€¢ Price: â‚¹4.50/kWh

00:05 â”€â”€â”€â”€> Preprocess (2 sec)
            â€¢ Normalize
            â€¢ Add forecasts
            â€¢ Build observation vector

00:07 â”€â”€â”€â”€> RL Agent decision (<1 sec)
            â€¢ action = model.predict(obs)
            â€¢ action = [450, 150, 0, 200, 0]

00:08 â”€â”€â”€â”€> Safety check (1 sec)
            â€¢ Verify limits
            â€¢ Clamp if needed

00:09 â”€â”€â”€â”€> Execute action (5 sec)
            â€¢ Send to battery inverter
            â€¢ Send to grid controller
            â€¢ Send to EV charger

00:14 â”€â”€â”€â”€> Log results (1 sec)
            â€¢ Save to database
            â€¢ Update dashboard

00:15 â”€â”€â”€â”€> Wait for next cycle...

15:00 â”€â”€â”€â”€> Repeat!
```

---

## ğŸš¨ Handling Edge Cases

### **Case 1: Sensor Failure**
```python
def get_solar_power_safe():
    try:
        return get_solar_power()
    except:
        # Fallback: Use forecast
        print("âš ï¸  Solar sensor failed, using forecast")
        return get_solar_forecast()
```

### **Case 2: Network Outage**
```python
# Store actions locally, execute when connection restored
action_queue = []

def execute_action_safe(action):
    try:
        execute_action(action)
    except requests.exceptions.ConnectionError:
        print("âš ï¸  Network down, queuing action")
        action_queue.append((time.time(), action))
```

### **Case 3: Model Predicts Unsafe Action**
```python
# Safety supervisor ALWAYS checks
action_safe, violations = safety.check_and_correct(action, obs)

if violations:
    # Log incident
    log_safety_violation(violations)
    
    # Alert operator
    send_alert("Model predicted unsafe action, corrected by safety system")
```

### **Case 4: Extreme Weather (Out of Distribution)**
```python
def is_observation_valid(obs):
    """Check if observation is within training distribution"""
    
    solar_power = obs[10]  # Normalized
    
    # Check if way outside training range
    if solar_power > 1.5 or solar_power < -0.5:
        print("âš ï¸  Observation outside training distribution!")
        return False
    
    return True

# In main loop
if not is_observation_valid(obs):
    print("ğŸ›‘ Switching to rule-based controller")
    action = baseline_controller(obs)  # Fallback
else:
    action = agent.select_action(obs)
```

---

## ğŸ“Š Monitoring & Logging

### **What to Log** (Every 15 min):

```python
log_entry = {
    'timestamp': datetime.now().isoformat(),
    
    # Inputs
    'observation': obs.tolist(),
    'solar_power': solar_power,
    'wind_power': wind_power,
    'load_power': load_power,
    'battery_soc': soc,
    'grid_price': price,
    
    # Outputs
    'action': action.tolist(),
    'action_safe': action_safe.tolist(),
    
    # Results
    'reward': reward,
    'cost': cost,
    'emissions': emissions,
    'safety_violations': violations,
    
    # System health
    'model_inference_time_ms': inference_time,
    'sensor_errors': sensor_errors,
}

# Save to database
save_to_influxdb(log_entry)

# Also save to CSV backup
with open('logs/realtime_log.csv', 'a') as f:
    writer = csv.DictWriter(f, fieldnames=log_entry.keys())
    writer.writerow(log_entry)
```

---

## ğŸ”„ When to Retrain (and When NOT To)

### âœ… **RETRAIN** if:
1. **Performance drops >20%** for >1 week
2. **Major equipment change** (new battery, new solar panel)
3. **Tariff structure changes** (different pricing)
4. **Seasonal shifts** (monsoon vs summer patterns)
5. **After 6-12 months** (periodic refresh)

### âŒ **DON'T RETRAIN** if:
1. **Normal weather variation** (cloudy day is fine!)
2. **Short-term performance dip** (<1 week)
3. **Sensor glitches** (fix sensor, not model)
4. **Model works fine** (if it ain't broke...)

### **Retraining Process**:
```python
# 1. Collect new data (at least 1 month)
new_data = collect_last_30_days()

# 2. Combine with old training data
combined_data = pd.concat([old_training_data, new_data])

# 3. Retrain (maybe fewer episodes since starting from good model)
agent.load("models/best_model.pt")  # Start from current
train(agent, combined_data, episodes=200)  # Fine-tune

# 4. Validate on held-out test set
test_performance = evaluate(agent, test_data)

# 5. Only deploy if better
if test_performance > current_performance:
    agent.save("models/best_model_v2.pt")
    print("âœ“ New model deployed")
else:
    print("âœ— New model worse, keeping old one")
```

---

## ğŸš€ Deployment Checklist

### **Before Going Live**:

- [ ] âœ… Model trained and validated
- [ ] âœ… Safety supervisor configured
- [ ] âœ… Normalizer stats saved (mean/std from training)
- [ ] âœ… Sensor APIs tested and working
- [ ] âœ… Action execution tested (on test bench)
- [ ] âœ… Logging system set up
- [ ] âœ… Dashboard connected
- [ ] âœ… Fallback controller ready
- [ ] âœ… Alert system configured
- [ ] âœ… Manual override accessible
- [ ] âœ… Team trained on system

### **First Day**:
- [ ] Run in **shadow mode** (agent decides, but don't execute)
- [ ] Compare agent decisions vs baseline
- [ ] Verify no safety violations

### **First Week**:
- [ ] Execute agent actions **with human supervision**
- [ ] Monitor performance closely
- [ ] Keep baseline controller ready to switch

### **After 1 Month**:
- [ ] Full autonomous operation
- [ ] Weekly performance reviews
- [ ] Monthly retraining evaluation

---

## ğŸ¯ Summary

### **Key Insights**:

1. **No retraining needed for normal operation**
   - Model learned patterns, applies to new data
   - Like a trained driver handles new roads

2. **Real-time = Read sensors â†’ Predict â†’ Execute**
   - 15-minute cycle
   - No learning during execution
   - Safety checks always

3. **Retrain only when necessary**
   - Major changes (equipment, tariffs)
   - Significant performance drop
   - Not for normal weather variation

4. **Always have fallbacks**
   - Safety supervisor
   - Baseline controller
   - Manual override

### **What You Need to Build**:

**Minimum** (to demo):
- âœ… Load model
- âœ… Construct observation from data
- âœ… Get action
- âœ… Show on dashboard

**Production** (to deploy):
- âœ… All above +
- âœ… Sensor integration (SCADA/IoT)
- âœ… Safety supervisor
- âœ… Logging system
- âœ… Fallback controller
- âœ… Monitoring dashboard
- âœ… Alert system

---

## ğŸ› ï¸ Complete Example: Simple Real-Time Simulator

```python
# deployment/simple_realtime.py

import torch
import numpy as np
import time
from datetime import datetime
from train_ppo_improved import ImprovedPPOAgent

# Load model
agent = ImprovedPPOAgent(obs_dim=90, action_dim=5)
agent.load("models/best_model.pt")

print("ğŸš€ Simple Real-Time Simulator")
print("This simulates new data coming in every 5 seconds")
print("â”€" * 60)

step = 0

while True:
    # Simulate getting NEW sensor data
    # (In real deployment, replace with actual sensor readings)
    hour = (step % 96) * 0.25  # 0-24 hours
    solar = 2000 * np.sin(np.pi * hour / 12) if 6 <= hour <= 18 else 0
    wind = np.random.uniform(100, 500)
    load = 1000 + 500 * np.sin(np.pi * hour / 12)
    soc = 0.5 + 0.3 * np.sin(np.pi * step / 48)
    price = 3.0 if 6 <= hour <= 9 or 18 <= hour <= 21 else 2.0
    
    # Build observation (simplified, real one has 90 dims)
    obs = np.array([
        hour/24, solar/3000, wind/1000, load/2000, soc, price/10
    ] + [0]*84, dtype=np.float32)  # Pad to 90 dims
    
    # Agent decision
    action = agent.select_action(obs, deterministic=True)
    
    # Display
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"\n[{timestamp}] Step {step} (Hour {hour:.1f})")
    print(f"  Inputs:  Solar={solar:.0f}kW Wind={wind:.0f}kW Load={load:.0f}kW")
    print(f"  Battery: SoC={soc:.1%} Price=â‚¹{price:.2f}/kWh")
    print(f"  AI Action: Battery1={action[0]:.0f}kW Battery2={action[1]:.0f}kW")
    print(f"            Grid={action[2]:.0f}kW EV={action[3]:.0f}kW")
    
    step += 1
    time.sleep(5)  # Wait 5 seconds (simulating 15 min)
```

**Run this**:
```bash
cd microgrid-ems-drl
python deployment/simple_realtime.py
```

---

**Ready to deploy? Let me know if you want me to create the complete deployment code!** ğŸš€
